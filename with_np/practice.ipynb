{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (5.0, 4.0)\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_pad(X, pad):\n",
    "    X_pad = np.pad(X, ((0,0), (pad, pad), (pad, pad), (0,0)), 'constant', constant_values = 0)\n",
    "    return X_pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape = (4, 3, 3, 2)\n",
      "x_pad.shape = (4, 7, 7, 2)\n",
      "[[ 0.90085595 -0.68372786]\n",
      " [-0.12289023 -0.93576943]\n",
      " [-0.26788808  0.53035547]]\n",
      "\n",
      "[[0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "x = np.random.randn(4, 3, 3, 2)\n",
    "x_pad = zero_pad(x, 2)\n",
    "print (\"x.shape =\", x.shape)\n",
    "print (\"x_pad.shape =\", x_pad.shape)\n",
    "\n",
    "print(x[1,1])\n",
    "print()\n",
    "print(x_pad[1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_single_step(a_slice_prev, W, b):\n",
    "    temp_ans = np.multiply(a_slice_prev, W) + b\n",
    "    '''\n",
    "    Basically take dot product of filter with extract of image and add bias and bam, you've got yourself an element\n",
    "    Add all of them\n",
    "    '''\n",
    "    return np.sum(temp_ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z = -23.16021220252078\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "a_slice_prev = np.random.randn(4, 4, 3)\n",
    "#Basically think of mini-slice with many slides or facets to contribute to volume (referred to as Nc)\n",
    "W = np.random.randn(4, 4, 3)\n",
    "b = np.random.randn(1, 1, 1)\n",
    "\n",
    "Z = conv_single_step(a_slice_prev, W, b)\n",
    "print(\"Z =\", Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_forward(A_prev, W, b, hparameters):\n",
    "    (m, nh_prev, nw_prev, nc_prev) = A_prev.shape\n",
    "    (f, f, nc_prev, nc_new) = W.shape\n",
    "    stride = hparameters['stride']\n",
    "    pad = hparameters['pad']\n",
    "    \n",
    "    nh_new = int((nh_prev - f + 2 * pad) / stride) + 1\n",
    "    nw_new = int((nw_prev - f + 2 * pad) / stride) + 1\n",
    "    \n",
    "    Z = np.zeros((m, nh_new, nw_new, nc_new))\n",
    "    \n",
    "    A_prev_padded = zero_pad(A_prev, pad)\n",
    "    \n",
    "    for i in range(m):\n",
    "        a_prev_temp = A_prev_padded[i]\n",
    "        for j in range(nh_new):\n",
    "            for k in range(nw_new):\n",
    "                for l in range(nc_new):\n",
    "                    top = j * stride\n",
    "                    bottom = top + f\n",
    "                    left = k * stride\n",
    "                    right = left + f\n",
    "                    \n",
    "                    a_slice = a_prev_temp[top:bottom, left:right, :]\n",
    "                    \n",
    "                    Z[i, j, k, l] = conv_single_step(a_slice, W[...,l], b[...,l])\n",
    "    assert(Z.shape == (m, nh_new, nw_new, nc_new))\n",
    "    \n",
    "    cache = (A_prev, W, b, hparameters)\n",
    "    return Z, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z's mean = 0.15585932488906465\n",
      "cache_conv[0][1][2][3] = [-0.20075807  0.18656139  0.41005165]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "A_prev = np.random.randn(10, 4, 4, 3)\n",
    "W = np.random.randn(2, 2, 3, 8)\n",
    "b = np.random.randn(1, 1, 1, 8)\n",
    "hparameters = {\"pad\" : 2,\n",
    "               \"stride\": 1}\n",
    "\n",
    "Z, cache_conv = conv_forward(A_prev, W, b, hparameters)\n",
    "print(\"Z's mean =\", np.mean(Z))\n",
    "print(\"cache_conv[0][1][2][3] =\", cache_conv[0][1][2][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pool_forward(A_prev, hparameters, mode = \"max\"):\n",
    "    A_new = []\n",
    "    (m, nh_old, nw_old, nc) = A_prev.shape\n",
    "    stride = hparameters[\"stride\"]\n",
    "    f = hparameters[\"f\"]\n",
    "    nh_new = int((nh_old - f) / stride) + 1\n",
    "    nw_new = int((nw_old - f) / stride) + 1\n",
    "    for i in range(m):\n",
    "        a_temp = A_prev[i]\n",
    "        a_new_temp = []\n",
    "        for j in range(nh_new):\n",
    "            a_mat = []\n",
    "            for k in range(nw_new):\n",
    "                a_row = []\n",
    "                for l in range(nc):\n",
    "                    top = j * stride\n",
    "                    bottom = top + f\n",
    "                    left = k * stride\n",
    "                    right = left + f\n",
    "                    a_slice = a_temp[top:bottom, left:right, l]    \n",
    "                    if(mode == \"max\"):\n",
    "                        num = np.max(a_slice)\n",
    "                    else:\n",
    "                        num = np.mean(a_slice)\n",
    "                    a_row.append(num)\n",
    "                a_mat.append(a_row)\n",
    "            a_new_temp.append(a_mat)\n",
    "        A_new.append(a_new_temp)\n",
    "        \n",
    "    cache = (A_prev, hparameters)\n",
    "    A_new = np.array(A_new)\n",
    "    assert(A_new.shape == (m, nh_new, nw_new, nc))    \n",
    "    return A_new, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mode = max\n",
      "A = [[[[1.74481176 1.6924546  2.10025514]]]\n",
      "\n",
      "\n",
      " [[[1.19891788 1.51981682 2.18557541]]]]\n",
      "\n",
      "mode = average\n",
      "A = [[[[-0.09498456  0.11180064 -0.14263511]]]\n",
      "\n",
      "\n",
      " [[[-0.09525108  0.28325018  0.33035185]]]]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "A_prev = np.random.randn(2, 4, 4, 3)\n",
    "hparameters = {\"stride\" : 1, \"f\": 4}\n",
    "\n",
    "A, cache = pool_forward(A_prev, hparameters)\n",
    "print(\"mode = max\")\n",
    "print(\"A =\", A)\n",
    "print()\n",
    "A, cache = pool_forward(A_prev, hparameters, mode = \"average\")\n",
    "print(\"mode = average\")\n",
    "print(\"A =\", A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_backward(dZ, cache):\n",
    "    (A_prev, W, b, hparameters) = cache\n",
    "    (m, nh_old, nw_old, nc_old) = A_prev.shape\n",
    "    (f, f, nc_old, nc) = W.shape\n",
    "    (m, nh_new, nw_new, nc) = dZ.shape\n",
    "    print(dZ.shape)\n",
    "    stride = hparameters[\"stride\"]\n",
    "    pad = hparameters[\"pad\"]\n",
    "    dA_prev = np.zeros(A_prev.shape)\n",
    "    dW = np.zeros(W.shape)\n",
    "    db = np.zeros(b.shape)\n",
    "    print(db.shape)\n",
    "    dA_padded = zero_pad(dA_prev, pad)\n",
    "    A_padded = zero_pad(A_prev, pad)\n",
    "    \n",
    "    for i in range(m):\n",
    "        for j in range(nh_new):\n",
    "            for k in range(nw_new):\n",
    "                top = j * stride\n",
    "                bottom = top + f\n",
    "                left = k * stride\n",
    "                right = left + f\n",
    "                for l in range(nc):\n",
    "                    for l1 in range(nc_old):\n",
    "                        #print(dA_padded[i, top:bottom, left:right, l1].shape)\n",
    "                        #print(dZ[i,j,k,l].shape)\n",
    "                        #print(W[:, :, l1, l].shape)\n",
    "                        dA_padded[i, top:bottom, left:right, l1] += dZ[i,j,k,l] * W[:, :, l1, l]\n",
    "                    dW[:, :, :, l] += dZ[i,j,k,l] * A_padded[i, top:bottom, left:right, :]\n",
    "                    db[:, :, :, l] += dZ[i,j,k,l]\n",
    "    dA_prev = dA_padded[:, pad:-pad, pad:-pad, :]\n",
    "    assert(dA_prev.shape == (m, nh_old, nw_old, nc_old))\n",
    "    return dA_prev, dW, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 7, 7, 8)\n",
      "(1, 1, 1, 8)\n",
      "dA_mean = 9.608990675868995\n",
      "dW_mean = 10.581741275547566\n",
      "db_mean = 76.37106919563735\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "dA, dW, db = conv_backward(Z, cache_conv)\n",
    "print(\"dA_mean =\", np.mean(dA))\n",
    "print(\"dW_mean =\", np.mean(dW))\n",
    "print(\"db_mean =\", np.mean(db))\n",
    "# print(dA.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mask_from_window(x):\n",
    "    mask = x == np.max(x)\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x =  [[ 1.62434536 -0.61175641 -0.52817175]\n",
      " [-1.07296862  0.86540763 -2.3015387 ]]\n",
      "mask =  [[ True False False]\n",
      " [False False False]]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "x = np.random.randn(2,3)\n",
    "mask = create_mask_from_window(x)\n",
    "print('x = ', x)\n",
    "print(\"mask = \", mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distribute_value(dz, shape):\n",
    "    (nh, nw) = shape\n",
    "    \n",
    "    average = dz / (nh * nw)\n",
    "    a = np.ones(shape) * average\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distributed value = [[0.5 0.5]\n",
      " [0.5 0.5]]\n"
     ]
    }
   ],
   "source": [
    "a = distribute_value(2, (2,2))\n",
    "print('distributed value =', a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pool_backward(dA, cache, mode = \"max\"):\n",
    "    (A_prev, hparameters) = cache\n",
    "    stride = hparameters[\"stride\"]\n",
    "    f = hparameters[\"f\"]\n",
    "    \n",
    "    (m, nh_old, nw_old, nc) = A_prev.shape\n",
    "    (m, nh_new, nw_new, nc) = dA.shape\n",
    "    \n",
    "    dA_prev = np.zeros(A_prev.shape)\n",
    "    for i in range(m):\n",
    "        for j in range(nh_new):\n",
    "            for k in range(nw_new):\n",
    "                top = j * stride\n",
    "                bottom = top + f\n",
    "                left = k * stride\n",
    "                right = left + f\n",
    "                for l in range(nc):\n",
    "                    temp_mat = dA_prev[i, top:bottom, left:right, l]\n",
    "                    if(mode == \"max\"):\n",
    "                        temp_mat = create_mask_from_window(temp_mat)\n",
    "                        dA_prev[i, top:bottom, left:right, l] += np.multiply(temp_mat, dA[i, j, k, l])\n",
    "                    else:\n",
    "                        shape = (f, f)\n",
    "                        dA_prev[i, top:bottom, left:right, l] += distribute_value(dA[i, j, k, l], shape)\n",
    "    return dA_prev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mode = max\n",
      "mean of dA =  0.14571390272918056\n",
      "dA_prev[1,1] =  [[ 0.98633519  1.11502079]\n",
      " [ 5.05844394 -1.68282702]\n",
      " [ 0.         -0.24863478]]\n",
      "\n",
      "mode = average\n",
      "mean of dA =  0.14571390272918056\n",
      "dA_prev[1,1] =  [[ 0.08485462  0.2787552 ]\n",
      " [ 1.26461098 -0.25749373]\n",
      " [ 1.17975636 -0.53624893]]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "A_prev = np.random.randn(5, 5, 3, 2)\n",
    "hparameters = {\"stride\" : 1, \"f\": 2}\n",
    "A, cache = pool_forward(A_prev, hparameters)\n",
    "dA = np.random.randn(5, 4, 2, 2)\n",
    "\n",
    "dA_prev = pool_backward(dA, cache, mode = \"max\")\n",
    "print(\"mode = max\")\n",
    "print('mean of dA = ', np.mean(dA))\n",
    "print('dA_prev[1,1] = ', dA_prev[1,1])  \n",
    "print()\n",
    "dA_prev = pool_backward(dA, cache, mode = \"average\")\n",
    "print(\"mode = average\")\n",
    "print('mean of dA = ', np.mean(dA))\n",
    "print('dA_prev[1,1] = ', dA_prev[1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
